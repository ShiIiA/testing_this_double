# -*- coding: utf-8 -*-
"""app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rRSegdTULlczjwu11IQzYDFAIJmlE8TF
"""

import os
import logging
import tempfile
import warnings
import streamlit as st
import pandas as pd
import numpy as np
import altair as alt
import plotly.express as px
import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision.models as models
import torchvision.transforms as transforms
from PIL import Image
from fairlearn.metrics import demographic_parity_difference, equalized_odds_difference
from sklearn.metrics import confusion_matrix, accuracy_score
from torchvision.models import DenseNet121_Weights
from transformers import AutoModelForCausalLM, AutoTokenizer

# Suppress meta parameter warnings
warnings.filterwarnings("ignore", message=".*meta parameter.*")

# ------------------------- Logging Configuration -------------------------
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# ------------------------- Page Configuration -------------------------
st.set_page_config(
    page_title="Gender Bias in Radiology",
    page_icon="üêç",
    layout="wide"
)

# ------------------------- Theme & Style Functions -------------------------
def set_styles():
    st.markdown(
        """
        <style>
        .stApp {background: linear-gradient(to bottom right, #ffffff, #e6f7ff); color: #000;}
        .stTitle {font-size: 36px !important; font-weight: bold; color: #000 !important;}
        div[data-testid="stProgressBar"] > div[role="progressbar"] > div {
            background: linear-gradient(to right, #4facfe, #00f2fe);
        }
        </style>
        """,
        unsafe_allow_html=True
    )

set_styles()

# ------------------------- Global Session State -------------------------
if "df" not in st.session_state:
    st.session_state.df = None
if "df_results" not in st.session_state:
    st.session_state.df_results = pd.DataFrame(columns=["Image_ID", "Gender", "Prediction", "Probability"])
if "chexagent_loaded" not in st.session_state:
    st.session_state.chexagent_loaded = False
if "device" not in st.session_state:
    st.session_state.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# ------------------------- Model Loading Functions -------------------------
@st.cache_resource(show_spinner=True)
def load_chexnet_model():
    model = models.densenet121(weights=DenseNet121_Weights.IMAGENET1K_V1)
    model.classifier = nn.Linear(1024, 2)
    model = model.to(st.session_state.device)
    model.eval()
    return model

try:
    chexnet_model = load_chexnet_model()
    st.sidebar.success("‚úÖ CheXNet Model Loaded Successfully!")
except Exception as e:
    logging.error("Error loading CheXNet model", exc_info=True)
    st.sidebar.error(f"üö® Error loading CheXNet model: {e}")

@st.cache_resource(show_spinner=True)
def load_chexagent():
    if not st.session_state.chexagent_loaded:
        model_name = "StanfordAIMI/CheXagent-2-3b"
        tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)
        model = AutoModelForCausalLM.from_pretrained(model_name, device_map="cpu", trust_remote_code=True).eval()
        st.session_state.chexagent_model = model
        st.session_state.chexagent_tokenizer = tokenizer
        st.session_state.chexagent_loaded = True
    return st.session_state.chexagent_model, st.session_state.chexagent_tokenizer

# ------------------------- Image Processing -------------------------
@st.cache_resource(show_spinner=True)
def preprocess_image(image):
    transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor()
    ])
    return transform(image).unsqueeze(0)

# ------------------------- Model Prediction -------------------------
def predict_with_models(image):
    results = {}

    # CheXNet Prediction
    tensor_img = preprocess_image(image).to(st.session_state.device)
    with torch.no_grad():
        logits = chexnet_model(tensor_img)
        probs = F.softmax(logits, dim=1)
        disease_prob = probs[0, 1].item()
        results["CheXNet"] = ("Disease Detected" if disease_prob >= 0.5 else "No Disease", disease_prob)

    # CheXagent Prediction
    try:
        model, tokenizer = load_chexagent()
        prompt = "Analyze the X-ray and return the detected disease."
        query = tokenizer.from_list_format([{"image": image}, {"text": prompt}])
        input_ids = tokenizer.apply_chat_template([{"from": "human", "value": query}], return_tensors="pt")
        output = model.generate(input_ids, max_new_tokens=128)[0]
        results["CheXagent"] = (tokenizer.decode(output[input_ids.size(1):-1]), None)
    except Exception as e:
        results["CheXagent"] = ("Error", None)

    return results

# ------------------------- Gender Bias Analysis -------------------------
def analyze_bias(df_results, df_truth, disease_col, image_col):
    merged = pd.merge(df_results, df_truth[[image_col, disease_col]], left_on="Image_ID", right_on=image_col)
    merged["Correct"] = merged["Prediction"].str.lower().str.strip() == merged[disease_col].str.lower().str.strip()

    demographic_parity = demographic_parity_difference(merged["Correct"], sensitive_features=merged["Gender"])
    equalized_odds = equalized_odds_difference(merged["Correct"], sensitive_features=merged["Gender"])

    return merged, demographic_parity, equalized_odds

# ------------------------- Streamlit Pages -------------------------
def model_comparison_page():
    st.title("ü§ñ Model Comparison")
    uploaded_images = st.file_uploader("Upload X-ray Images", type=["png", "jpg", "jpeg"], accept_multiple_files=True)

    if uploaded_images:
        for img in uploaded_images:
            image = Image.open(img).convert("RGB")
            st.image(image, caption=f"Uploaded: {img.name}", width=300)

            # Run Predictions
            results = predict_with_models(image)
            st.write(f"**CheXNet Prediction:** {results['CheXNet'][0]} | **Probability:** {results['CheXNet'][1]:.2%}")
            st.write(f"**CheXagent Prediction:** {results['CheXagent'][0]}")

def gender_bias_analysis_page():
    st.title("‚öñÔ∏è Gender Bias Analysis")
    df_results = st.session_state.get("df_results", pd.DataFrame(columns=["Image_ID", "Gender", "Prediction"]))
    df_truth = st.session_state.get("df", None)

    if df_truth is None or df_results.empty:
        st.info("Upload images and ground truth labels first.")
        return

    disease_col = st.selectbox("Select Ground-Truth Disease Column:", df_truth.columns.tolist())
    image_col = st.selectbox("Select Image ID Column:", df_truth.columns.tolist())

    if st.button("Analyze Bias"):
        merged, demographic_parity, equalized_odds = analyze_bias(df_results, df_truth, disease_col, image_col)
        st.write("Merged Predictions with Ground Truth:")
        st.dataframe(merged.head())
        st.write(f"**Demographic Parity Difference:** {demographic_parity:.4f}")
        st.write(f"**Equalized Odds Difference:** {equalized_odds:.4f}")

# ------------------------- Sidebar Navigation -------------------------
st.sidebar.title("Navigation")
selected_page = st.sidebar.radio("Go to", ["ü§ñ Model Comparison", "‚öñÔ∏è Gender Bias Analysis"])

if selected_page == "ü§ñ Model Comparison":
    model_comparison_page()
elif selected_page == "‚öñÔ∏è Gender Bias Analysis":
    gender_bias_analysis_page()